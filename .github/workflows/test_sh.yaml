# This is a test workflow the other (self-hosted runner based) workflows rely on
name: Test workflow (self-hosted)

# Controls when the action will run. This is a reusable workflow.
on:
  workflow_call:
    # Inputs the workflow accepts.
    # Specify branches using the refspec-like syntax: <user>:<branch>
    inputs:
      locations:
        description: 'Branch locations (JSON array string)'
        default: '{ "xobjects_location":"xsuite:main" ,
        "xdeps_location":"xsuite:main",
        "xpart_location":"xsuite:main",
        "xtrack_location":"xsuite:main",
        "xfields_location":"xsuite:main",
        "xmask_location":"xsuite:main",
        "xcoll_location":"xsuite:main"}'
        required: false
        type: string
      pytest_options:
        description: Additional pytest options
        required: false
        type: string
        default: ''
      test_contexts:
        required: false
        type: string
        default: 'ContextCpu;ContextCpu:auto;ContextCupy;ContextPyopencl'
      platform:
        required: true
        type: string
      suites:
        description: a list of the suites to run as a JSON string
        required: false
        type: string
        default: '["xobjects", "xdeps", "xpart", "xtrack", "xfields", "xcoll"]'

env:
  with_gpu: ${{ contains(inputs.test_contexts, 'Cupy') || contains(inputs.test_contexts, 'Pyopencl') }}

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# The jobs are all run in independent environments. Here we will run a separate job
# for each of the test suites specified in the matrix below.

# This workflow calls build_image_sh.yaml workflow passing the specified
# The Job Trigger and Download image from GitHub Artifact 
# branches as inputs
jobs:
  trigger-build-image:
    uses: ./.github/workflows/build_image_sh.yaml
    with:
      locations: ${{ inputs.locations }}

  download-image:
    needs: trigger-build-image
    runs-on: [self-hosted, "${{ inputs.platform }}"]
    outputs:
      image_id: ${{ steps.load-image.outputs.image_id }}
    steps:
      - name: Checkout the repo
        id: checkout-repo
        uses: actions/checkout@v3

      - name: Download Docker image artifact
        id: get-artifact
        uses: actions/download-artifact@v4
        with:
          name: docker-image
          path: docker-image

      - name: Load Docker image
        id: load-image
        run: |
          IMAGE=$(gzip -dc docker-image/*.tar.gz | docker load | cut -d ' ' -f 3)
          if [[ $? -ne 0 ]]; then
              echo "Failed to load Docker image"
              exit 1
          fi
          echo "Loaded Image: $IMAGE"
          echo "image_id=$IMAGE" >> $GITHUB_OUTPUT
      
  # Print out some stuff about the test environment
  image-sanity-checks:
    runs-on: [self-hosted, "${{ inputs.platform }}"]
    needs: download-image
    env: 
      image_id: ${{ needs.download-image.outputs.image_id }}
    steps:
      - name: CUDA/ROCm info
        if: ${{ env.with_gpu == 'true' }}
        run: docker run --rm --gpus all ${image_id} bash -c "nvidia-smi || rocm-smi"
      - name: OpenCL info
        if: ${{ env.with_gpu == 'true' }}
        run: docker run --rm --gpus all ${image_id} clinfo
      - name: Package paths
        run: docker run --rm --gpus all ${image_id} python3 /opt/xsuite/xtrack/examples/print_package_paths.py
      - name: List dependencies
        run: docker run --rm --gpus all ${image_id} pip freeze

  # Run the tests for each repo in parallel in a test container
  run-tests:
    runs-on: [self-hosted, "${{ inputs.platform }}"]
    needs: [download-image, image-sanity-checks]
    timeout-minutes: 540
    strategy:
      fail-fast: false
      matrix:
        test-suite: ${{ fromJson(inputs.suites) }}
    steps:
      - name: Run pytest
        env:
          image_id: ${{ needs.download-image.outputs.image_id }}
          test_contexts: ${{ inputs.test_contexts }}
          pytest_options: ${{ inputs.pytest_options }}
        run: |
            mkdir -p reports/${{ matrix.test-suite }}
            docker run --rm --gpus all \
              --env XOBJECTS_TEST_CONTEXTS="${test_contexts}" \
              --env PYTEST_ADDOPTS="${pytest_options}" \
              -v $PWD/reports/${{ matrix.test-suite }}:/opt/reports:Z \
              ${image_id} \
              /opt/run_tests.sh /opt/xsuite/${{ matrix.test-suite }}/tests | tee reports/${{ matrix.test-suite }}/results.txt
      
      - name: List report files
        run: |
            echo "Listing files in reports/${{ matrix.test-suite }}:"
            ls -lah reports/${{ matrix.test-suite }}

      - name: Extract Errors and Summarize in Markdown
        run: |
            echo "## Test Summary" ${{ matrix.test-suite }}>> $GITHUB_STEP_SUMMARY
            results_file="reports/${{ matrix.test-suite }}/results.txt"
              if [ -f "$results_file" ]; then
                echo "Results file found, processing..."

                sed -i -e 's/\x1b\[[0-9;]*m//g' -e 's/^> /\\> /g' $results_file
              
                passed=$(grep -c PASSED $results_file || true)
                failed=$(grep "FAILED.*xsuite" $results_file | grep -P 'FAILED.* - ' | sed -E 's/.*\] (.*::[^ ]+).* - .*/\1/' | sort | uniq | wc -l)
                skipped=$(grep -c SKIPPED $results_file || true)
                
                echo "| Result | Number |" >> $GITHUB_STEP_SUMMARY
                echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
                echo "| Passed ✅| $passed |" >> $GITHUB_STEP_SUMMARY
                echo "| Failed ❌| $failed |" >> $GITHUB_STEP_SUMMARY
                echo "| Skipped ⏭️| $skipped |" >> $GITHUB_STEP_SUMMARY

                if [ $failed -ne 0 ]; then
                  echo "### 🔴 Failed Tests" >> $GITHUB_STEP_SUMMARY
                  grep "FAILED.*xsuite" $results_file | grep -P 'FAILED.* - ' | sed -E 's/.*\] (.*::[^ ]+).* - (.*)/\1 - \2/' | sort | uniq | while read -r failure; do
                    echo "- $failure" >> $GITHUB_STEP_SUMMARY
                    
                    echo "<details><summary>Click here to view the error details</summary><p>" >> $GITHUB_STEP_SUMMARY
                    echo '```'

                    echo "Debug: Failure detail extraction for $failure"
                    test_name=$(echo "$failure" | sed -E 's/.*::([^\-]+).* - .*/\1/' | sed -E 's/\x1b\[[0-9;]*m//g' )
                    test_name=$(echo "$test_name" | sed 's/[][]/\\&/g')
                    echo "Debug: Looking for start of error details for $test_name"
                    error_start_line=$(grep -n "____________________ ${test_name} ____________________" $results_file | cut -d: -f1)
                    echo "Debug: Start line found at $error_start_line"
                    error_end_line=$(tail -n +$((error_start_line + 1)) $results_file | grep -nm 1 "^-.*Captured stdout call.*-$" | cut -d: -f1)
                    if [[ ! -z "$error_start_line" ]]; then
                      error_end_line=$(tail -n +$((error_start_line + 1)) $results_file | grep -nm 1 "^-.*Captured stdout call.*-$" | cut -d: -f1)
                      if [[ ! -z "$error_end_line" ]]; then
                          absolute_error_end_line=$((error_start_line + error_end_line - 1))
                          echo "Debug: End line found at $absolute_error_end_line"
                          sed -n "${error_start_line},${absolute_error_end_line}p" $results_file | sed 's/^>/\\>/' >> $GITHUB_STEP_SUMMARY
                      fi
                    fi
                    echo '```' 
                    echo "</p></details>" >> $GITHUB_STEP_SUMMARY
                  done
                fi
              else
                echo "No test results found." >> $GITHUB_STEP_SUMMARY
              fi

  wait:
    runs-on: [self-hosted, "${{ inputs.platform }}"]
    needs: [download-image, run-tests]
    if: success() || failure()
    steps:
      - name: Wait
        run: sleep 300

  # Cleanup after the tests by removing the image and making sure there are
  # no unused images and stopped containers
  teardown:
    runs-on: [self-hosted, "${{ inputs.platform }}"]
    needs: [download-image, wait]
    env: 
      image_id: ${{ needs.download-image.outputs.image_id }}
    if: always()
    steps:
      - name: Stop the containers and remove the image
        run: |
          docker container stop \
            $(docker ps -q --filter ancestor=${image_id}) || true
          docker container rm --volumes \
            $(docker ps -qa --filter ancestor=${image_id}}) || true
          docker image rm ${image_id}